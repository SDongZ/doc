流媒体开发
http://bbs.rosoo.net/forum.php


---------------------------------------------------------------------------

---------------------------------------------------------------------------

---------------------------------------------------------------------------

---------------------------------------------------------------------------

---------------------------------------------------------------------------
声音的 线路输入 麦克风 区别问题 。line in  与 mic 区别
音频输入是输入双声道的输入，麦克风接口只能输入单声道
线路输入和mic输入貌似是输入阻抗不同
线路输入（LINE IN）：输入阻抗一般10K欧姆以上，输入电平-20db，适合接驳输出阻抗为600欧姆的各种CD、VCD、DVD和调谐器等设备
话筒输入（MIC IN)：输入阻抗为4.7K欧姆以下，输入电平-35db以下，适合接驳各种话筒
音频输入是输入已经调制好的音频信号，麦克风接口只能输入未经调制的电信号
线路输入口可以用作麦克风的输入口，但反过来不行
麦克风输入口的内部放大器的增益要高于线路输入的部分（麦克风得到的信号电平要比线路输入的电平低）
Line in和Mic in两个接口，翻译成中文就是“线性输入”和“麦克风输入”
Line in端口：该端口主要用于连接电吉他、电子琴、合成器等外界设备的音频信号输出的录音，由于这些设备本身输出功率就比较大，因此需要连接到Line in端口录音，当然使用它们录音从某种程度上也可以被称为外部设备的“内录”。一般您使用的声卡越好，Line in里的噪音就会越低，录制效果也会比较好
Mic in端口：这要是连接麦克风录音使用的。但是这个端口和Line in的区别在于它有前置放大器，换言之麦克风本身输出功率小，因此必须要有一个外部的放大设备来放大音频信号。这个端口就是起到这个作用。有兴趣的朋友可以尝试一下把你的麦克风直接连接到Line in端口录音……没有声音或者声音很小对吧？！道理很简单，麦克风的信号没有被放大，自然效果就不好了
特别要强调的一点是：外部的电吉他、合成器这类音频设备万不可直接连接到Mic in上录音，因为这种连接轻则录音时信号会严重削顶失真，重则损毁声卡这类硬件设备，切记切记
---------------------------------------------------------------------------
---------------------------------------------------------------------------
audio uncompressed data ( PCM )
PCM Wave Format

we store each sample using encoding with 16 bits per sample, in a short array buffer of two bytes
http://stackoverflow.com/questions/8686355/how-to-change-the-volume-of-a-pcm-data-stream-failed-experiment
http://www.ypass.net/blog/2010/01/pcm-audio-part-3-basic-audio-effects-volume-control/
http://www.ypass.net/blog/2010/01/pcm-audio-part-1-what-is-pcm/
http://stackoverflow.com/questions/2527290/visualizing-volume-of-pcm-samples
http://stackoverflow.com/questions/535246/sound-pressure-display-for-wave-pcm-data
you can simply compute the log-energy on some time franmes of the signal:
 split the signal every N samples, compute 10*log(sum(xn**2)) where x are the N samples, and you get a value in the dB domain
calculate dB from PCM WAV file

You could do something like find the root mean square

sqrt( (1/n) sum( (x_i)^2 ;i=0,n-1))

of consecutive values (1000, say) and then log-transform it.
db = 20 * log10(Pa/ref Pa)
http://stackoverflow.com/questions/2917762/android-pcm-bytes
 signed 16-bit little-endian mono @ 44.1kHz
---------------------------------------------------------------------------
音视频编码知识
interleaved  / interlaced  (隔行扫描)
去交错：将交错式扫描讯号(interlaced video signal)转换成非交错式扫描(non-interlaced)讯号，业内一般称之为“去场”
去交错来将交错式影像转换为渐进式影像
交错式影像从拍摄、传输到储存都是使用交错格式，相邻的场被拍摄的时间并不相同，相邻的两个场并不能完美的结合在一起
每次只传输和显示一半的扫描线，既场
一场只包含偶数行 (即偶场) 或者奇数行 (即奇场) 扫描线  （这里的奇偶数，是指行号）
由于视觉暂留效应，人眼不会注意到两场只有一半的扫描行，而会看到完整的一帧
摄像机采集的方式和隔行扫描显示的方式是完全相同的
摄像机采集图像时，偶场和奇场不是同时采集的。例如在一个每秒50场的摄像机中，第122行和124行的采集在第121行和123行的采集大约1/50秒之后进行
当代的显示器和电视中，由于非隔行扫描显示的刷新率的提高，使用者已经不会再感觉到闪烁现象，因此，隔行扫描技术逐渐被取代
---------------------------------------------------------------------------
Visualizing volume of PCM samples

A crude(简略，原生) volume calculation would be rms (root mean square), i.e. taking a rolling average of the square of the samples and take the square root of that average. This will give you a postive quantity when there is some sound; the quantity is related to the power represented in the waveform.
RMS is averaging the area displaced by the signal, the area between the waveform and the linear zero line (not 0dB, but the axis)
In the C++ Boost libraries, why is there a ".ipp" extension on some header files?
If you want to split up your template sources into interface and implementation (there are lots of good reasons to do that, including controlling instantiation), you can't very well use the same name (foo.hpp) twice, and foo.cpp wouldn't be appropriate for either one. foo.ipp clearly delineates the file as an implementation file intended to be #included in foo.hpp.
http://www.geosci.usyd.edu.au/users/jboyden/vad/#chapter-pcm-vis
Visualising audio data

calculate volume from pcm data
http://www.kvraudio.com/forum/viewtopic.php?t=291758
http://stackoverflow.com/questions/2445756/how-can-i-calculate-audio-db-level
dB = 20 * log10(amplitude)
amplitude = 14731 / 32767
         = 0.44

dB = 20 * log10(0.44)
  = -7.13
线性增长(linear)，转为(对数)级数增长(logarithmic)（类似与通常说的“翻番”――2、4、8、16、32、64、128）。
You may convert percentage (linear) to dB (logarithmic) by using the following equations:
dB = 10 log(1 + X)
Example X = 1%
Thus,
dB = 10 log(1 + 0.01)
dB = 0.0432
e在科学技术中用得非常多，一般不使用以10为底数的对数。以e为底数，许多式子都能得到简化，用它是最“自然”的，所以叫“自然对数”。
以常数e为底数的对数叫做自然对数，记作ln N(N>0)
e是一个无限不循环小数，其值约等于2.718281828…，它是一个超越数
自然指数―是以e作为基的指数函数
自然对数（英语：Natural logarithm）是以e为基的对数函数（）
对数表是指，通过计算得出从1开始各个整数的对数（现在一般用常用对数），所编排成的表格
首先，假设我们要计算1055×8712。
查表得lg1055≈3.023，lg8712≈3.940。
将两数相加，得6.963。
计算。
验算：直接计算1055×8712=9191160，可见有一定误差。在对数位数取值更多时，数值将更为精确。
根据对数运算的基本公式，可知且 (b≠0)，因此在知道两大数的对数情况下，可很快计算出两数的积和商
---------------------------------------------------------------------------
Detect silence when recording

分贝（decibel）是量度两个相同单位之数量比例的单位，主要用于度量声音强度，常用dB表示。“分”（deci-）指十分之一，个位是“贝”（bel），但一般只采用分贝
常用的空气参考声压为 = 20 μPa（微帕斯卡） (rms)，它通常被认为是人类的最少听觉响应值（大约是3米以外飞行的蚊子声音）
分贝(dB)是十分之一贝尔(B): 1B = 10dB
http://msdn.microsoft.com/en-us/library/ee663260(v=vs.85).aspx
http://msdn.microsoft.com/en-us/library/dd370805(v=vs.85).aspx
Core Audio Interfaces
---------------------------------------------------------------------------
http://stackoverflow.com/questions/2534595/get-master-sound-volume-in-c-sharp
http://stackoverflow.com/questions/5890499/pcm-audio-amplitude-values
http://www.sae.edu/reference_material/audio/pages/Microphones.htm
音箱的原理，上下震动，所有就是正负值。（如果是unsigned, 8bit，则127表示音量为零）
声音格式
PCM unsigned, 8bit mono,11025 Hz
signed 16-bit little-endian mono @ 44.1kHz
S16LE (signed 16-bit little-endian)
S32BE (signed 32-bit big-endian)
0~65535  unsigned short
-32768至+32767  short

音量范围
Volume levels are in the range 0.0 to 1.0
高级Linux声音体系（英语：Advanced Linux Sound Architecture，缩写为ALSA）是Linux内核中，为声卡提供的驱动组件，以替代原先的OSS（开放声音系统）

How to get the dB(or any kind of volume) level from a microphone in java?  amplitude[??mpl??tud, -?tjud]振幅

振幅是在波动或振动中距离平衡位置或静止位置的最大位移。符号A，单位米。振幅永为正值
http://stackoverflow.com/questions/5808913/how-to-get-the-dbor-any-kind-of-volume-level-from-a-microphone-in-java
由振幅转为分贝
http://stackoverflow.com/questions/2167513/iphone-how-to-measure-amplitude-of-a-pcm-coded-signal
float amplitude( short * s ) {
        if( *s < 0 ) return ( ( float )abs( *s ) ) / 32768;  也可以写成 ( float )abc( *s ) / 32768;
        else return ( ( float ) *s ) / 32767;
}
float amplitude_avg( short *s, int cnt ) {
        float total_amplitude = 0;
        for( int i = 0; i < cnt; i++ ) {
                total_amplitude += amplitude( s + i );
        }
        return total_amplitude / cnt;
}

---------------------------------------------------------------------------
Well it's all about time. FFMpeg uses in fact three different timestamps in different bases in order to work.
tbn = the time base in AVStream that has come from the container
tbc = the time base in AVCodecContext for the codec used for a particular stream
tbr = tbr is guessed from the video stream and is the value users want to see when they look for the video frame rate
tbn和tbc应该都是在相应层上的时间单元
tbn=2997就相当于在视频流层把1s的时间分成了2997个时间单元，如此精细可以更好的与其他流比如音频流同步，对应着fps=29.97就表示每100个时间单元中有一帧
1200k tbn代表文件层（st）的时间精度，即1S=1200k
50 tbc代表视频层（st->codec）的时间精度，即1S=50
25   tbr代表帧率
90k tbn代表文件层（st）的时间精度，即1S=1200k，和duration相关；
50   tbc代表视频层（st->codec）的时间精度，即1S=50，和strem->duration和时间戳相关
---------------------------------------------------------------------------

sqcif
               128x96
           qcif
               176x144
           cif 352x288
           4cif
               704x576
           qqvga
               160x120
           qvga
               320x240
           vga 640x480
           svga
               800x600
           xga 1024x768
           uxga
               1600x1200
           qxga
               2048x1536
           sxga
               1280x1024
           qsxga
               2560x2048
           hsxga
               5120x4096
           wvga
               852x480
           wxga
               1366x768
           wsxga
               1600x1024
           wuxga
               1920x1200
           woxga
               2560x1600
           wqsxga
               3200x2048
           wquxga
               3840x2400
           whsxga
               6400x4096
           whuxga
               7680x4800
           cga 320x200
           ega 640x350
           hd480
               852x480
           hd720
               1280x720
           hd1080
               1920x1080



---------------------------------------------------------------------------
[VID-AUD] yuv 
YUV，是一种颜色编码方法。
YUV是编译true-color颜色空间（color space）的种类，Y'UV, YUV, YCbCr，YPbPr等专有名词都可以称为YUV，彼此有重叠。
“Y”表示明亮度（Luminance、Luma），“U”和“V”则是色度、浓度（Chrominance、Chroma），
Y'UV, YUV, YCbCr, YPbPr常常有些混用的情况，
其中YUV和Y'UV通常用来描述模拟信号，而相反的YCbCr与YPbPr则是用来描述数位的影像信号，
例如在一些压缩格式内MPEG、JPEG中，但在现今，YUV通常已经在电脑系统上广泛使用。

YUV Formats分成两个格式：
紧缩格式（packed formats）：将Y、U、V值储存成Macro Pixels阵列，和RGB的存放方式类似。
平面格式（planar formats）：将Y、U、V的三个份量分别存放在不同的矩阵中。

紧缩格式（packed format）中的YUV是混合在一起的，对于YUV4:4:4格式而言，用紧缩格式很合适的，因此就有了UYVY、YUYV等。

平面格式（planar formats）是指每Y份量，U份量和V份量都是以独立的平面组织的，
也就是说所有的U份量必须在Y分量后面，而V份量在所有的U份量后面，此一格式适用于采样（subsample）。
平面格式（planar format）有I420（4:2:0）、YV12、IYUV等



[VID-AUD]
yuy2 格式
A digital, color-difference component video picture format identified by the FOURCC code YUY2.

YUY2及常见表示方法[编辑]
YUY2（和YUYV）格式为像素保留Y，而UV在水平空间上相隔二个像素采样一次（Y0 U0 Y1 V0），（Y2 U2 Y3 V2）…
其中，（Y0 U0 Y1 V0）就是一个macro-pixel（宏像素），它表示了2个像素，（Y2 U2 Y3 V2）是另外的2个像素。

以此类推，再如：Y41P（和Y411）格式为每个像素保留Y分量，而UV分量在水平方向上每4个像素采样一次。一个宏像素为12个字节，实际表示8个像素。
图像数据中YUV分量排列顺序如下：（U0 Y0 V0 Y1 U4 Y2 V4 Y3 Y4 Y5 Y6 Y7）

YVYU UYVY[编辑]
YVYU, UYVY格式跟YUY2类似，只是排列顺序有所不同。Y211格式是Y每2个像素采样一次，而UV每4个像素采样一次。AYUV格式则有一Alpha通道。

YV12[编辑]
YV12格式与IYUV类似，每个像素都提取Y，在UV提取时，将图像2 x 2的矩阵，每个矩阵提取一个U和一个V。
YV12格式和I420格式的不同处在V平面和U平面的位置不同。
在YV12格式中，U平面紧跟在Y平面之后，然后才是V平面（即：YUV）；但I420则是相反（即：YVU）。NV12与YV12类似，效果一样，YV12中U和V是连续排列的，而在NV12中，U和V就交错排列的。
排列举例： 2*2图像YYYYUV； 4＊4图像YYYYYYYYYYYYYYYYUUUUVVVV

FourCC全称Four-Character Codes，是由4个字符（4 bytes）组成，是一种独立标示视频数据流格式[来源请求]的四字节，在wav、avi档案之中会有一段FourCC来描述这个AVI档案，是利用何种编码器来编码的。因此wav、avi大量存在等于“IDP3”的FourCC

一般用宏生成FOURCC，FOURCC是由4个字符拼接而成的，生成FOURCC的传统方法是: 

　　#define MAKE_FOURCC(a,b,c,d) \ 

　　( ((uint32_t)d) | ( ((uint32_t)c) << 8 ) | ( ((uint32_t)b) << 16 ) | ( ((uint32_t)a) << 24 ) )

fourcc，视频播放软件通过查询 FourCC 代码并且寻找与 FourCC 代码相关联的视频解码器来播放特定的视频流。



History[edit]
In 1985, Electronic Arts introduced the Interchange File Format (IFF) meta-format (family of file formats), originally devised for use on the Amiga. These files consisted of a sequence of "chunks" which could contain arbitrary data, each chunk prefixed by a four-byte ID. The IFF specification explicitly mentions that the origins of the FourCC idea lie with Apple.[1]
This IFF was adopted by a number of developers including Apple for AIFF files and Microsoft for RIFF files (which were used as the basis for the AVI and WAV file format). Apple referred to many of these codes as OSTypes. Microsoft and Windows developers refer to their four-byte identifiers as FourCCs or Four Character Codes. FourCC codes were also adopted by Microsoft to identify data formats used in DirectX, specifically within DirectShow and DirectX Graphics

Common uses[edit]
One of the most well-known uses of FourCCs is to identify the video codec used in AVI files. Common identifiers include DIVX, XVID, and H264. For audio codecs, AVI and WAV files use a two-byte identifier, usually written in hexadecimal (such as 0055 for MP3). In QuickTime files, these two-byte identifiers are prefixed with the letters 'ms' to form a four-character code. RealMedia files also use four character codes; however, the actual codes used differ from those found in AVI or QuickTime files.
Other file formats that make important use of the four-byte ID concept are the Standard MIDI File Format, the PNG image file format, the 3DS (3D Studio Max) mesh file format and the ICC profile format.








---------------------------------------------------------------------------

硬件，传输线
http://en.wikipedia.org/wiki/Serial_digital_interface
http://baike.baidu.com/subview/840209/5111289.htm?fr=aladdin
SDI(Serial Digital Interface) 接口即数字串行接口。
人们常在SDI信号中嵌入数字音频信号，也就是将数字音频信号插入到视频信号的行、场同步脉冲（行、场消隐）期间与数字分量视频信号同时传输
SDI接口不能直接传送压缩数字信号，数字录像机、硬盘等设备记录的压缩信号重放后，必须经解压并经SDI接口输出才能进入SDI系统。
如果反复解压和压缩，必将引起图像质量下降和延时增加，为此各种不同格式的数字录像机和非线性编辑系统，规定了自己的用于直接传输压缩数字信号的接口